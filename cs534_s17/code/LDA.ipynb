{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Discriminant Analysis\n",
    "\n",
    "* Adapted from Jupyter Notebook by [Sebastian Raschka](https://github.com/rasbt/pattern_classification/blob/master/dimensionality_reduction/projection/linear_discriminant_analysis.ipynb)\n",
    "\n",
    "## Dataset\n",
    "This notebook uses the famous \"Iris\" dataset that can be found on the [UCI machine learning repository](https://archive.ics.uci.edu/ml/datasets/Iris). It contains measurements for 150 iris flowers from three different species.\n",
    "\n",
    "The three classes in the Iris dataset:\n",
    "* Iris-setosa (n=50)\n",
    "* Iris-versicolor (n=50)\n",
    "* Iris-virginica (n=50)\n",
    "\n",
    "The four features of the Iris dataset:\n",
    "* sepal length in cm\n",
    "* sepal width in cm\n",
    "* petal length in cm\n",
    "* petal width in cm\n",
    "\n",
    "![iris](http://joyceho.github.io/images/iris_petal_sepal.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.io.parsers.read_csv(\n",
    "    filepath_or_buffer='https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', \n",
    "    header=None, \n",
    "    sep=',', \n",
    "    )\n",
    "feature_dict = {i:label for i,label in zip(\n",
    "                range(4),\n",
    "                  ('sepal length in cm', \n",
    "                  'sepal width in cm', \n",
    "                  'petal length in cm', \n",
    "                  'petal width in cm', ))}\n",
    "df.columns = [l for i,l in sorted(feature_dict.items())] + ['class label']\n",
    "df.dropna(how=\"all\", inplace=True) # to drop the empty line at file-end\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is more convenient to work with numerical values, we will use the `LabelEncode` from the `scikit-learn` library to convert the class labels into numbers: `1, 2, and 3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = df[[0,1,2,3]].values \n",
    "y = df['class label'].values \n",
    "\n",
    "enc = LabelEncoder()\n",
    "label_encoder = enc.fit(y)\n",
    "y = label_encoder.transform(y) + 1\n",
    "\n",
    "label_dict = {1: 'Setosa', 2: 'Versicolor', 3:'Virginica'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms and feature selection\n",
    "\n",
    "Just to get a rough idea how the samples of our three classes $\\omega_1$, $\\omega_2$ and $\\omega_3$ are distributed, let us visualize the distributions of the four different features in 1-dimensional histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12,6))\n",
    "\n",
    "for ax,cnt in zip(axes.ravel(), range(4)):  \n",
    "    \n",
    "    # set bin sizes\n",
    "    min_b = math.floor(np.min(X[:,cnt]))\n",
    "    max_b = math.ceil(np.max(X[:,cnt]))\n",
    "    bins = np.linspace(min_b, max_b, 25)\n",
    "    \n",
    "    # plottling the histograms\n",
    "    for lab,col in zip(range(1,4), ('blue', 'red', 'green')):\n",
    "        ax.hist(X[y==lab, cnt],\n",
    "                   color=col, \n",
    "                   label='class %s' %label_dict[lab], \n",
    "                   bins=bins,\n",
    "                   alpha=0.5,)\n",
    "    ylims = ax.get_ylim()\n",
    "    \n",
    "    # plot annotation\n",
    "    leg = ax.legend(loc='upper right', fancybox=True, fontsize=8)\n",
    "    leg.get_frame().set_alpha(0.5)\n",
    "    ax.set_ylim([0, max(ylims)+2])\n",
    "    ax.set_xlabel(feature_dict[cnt])\n",
    "    ax.set_title('Iris histogram #%s' %str(cnt+1))\n",
    "    \n",
    "    # hide axis ticks\n",
    "    ax.tick_params(axis=\"both\", which=\"both\", bottom=\"off\", top=\"off\",  \n",
    "            labelbottom=\"on\", left=\"off\", right=\"off\", labelleft=\"on\")\n",
    "\n",
    "    # remove axis spines\n",
    "    ax.spines[\"top\"].set_visible(False)  \n",
    "    ax.spines[\"right\"].set_visible(False) \n",
    "    ax.spines[\"bottom\"].set_visible(False) \n",
    "    ax.spines[\"left\"].set_visible(False)    \n",
    " \n",
    "axes[0][0].set_ylabel('count')\n",
    "axes[1][0].set_ylabel('count')\n",
    "    \n",
    "fig.tight_layout()       \n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From just looking at these simple graphical representations of the features, we can already tell that the petal lengths and widths are likely better suited as potential features two separate between the three flower classes. In practice, instead of reducing the dimensionality via a projection (here: LDA), a good alternative would be a feature selection technique. For low-dimensional datasets like Iris, a glance at those histograms would already be very informative. Another simple, but very useful technique would be to use feature selection algorithms, which I have described in more detail in another article: [Feature Selection Algorithms in Python](http://sebastianraschka.com/Articles/2014_sequential_sel_algos.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA via scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# LDA\n",
    "sklearn_lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "X_lda_sklearn = sklearn_lda.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_scikit_lda(X, title):\n",
    "    \n",
    "    ax = plt.subplot(111)\n",
    "    for label,marker,color in zip(\n",
    "        range(1,4),('^', 's', 'o'),('blue', 'red', 'green')):\n",
    "        \n",
    "        plt.scatter(x=X[:,0][y == label],\n",
    "                    y=X[:,1][y == label] * -1, # flip the figure\n",
    "                    marker=marker,\n",
    "                    color=color,\n",
    "                    alpha=0.5,\n",
    "                    label=label_dict[label])\n",
    "  \n",
    "    plt.xlabel('LD1')\n",
    "    plt.ylabel('LD2')\n",
    "\n",
    "    leg = plt.legend(loc='upper right', fancybox=True)\n",
    "    leg.get_frame().set_alpha(0.5)\n",
    "    plt.title(title)\n",
    "    \n",
    "    # hide axis ticks\n",
    "    plt.tick_params(axis=\"both\", which=\"both\", bottom=\"off\", top=\"off\",  \n",
    "            labelbottom=\"on\", left=\"off\", right=\"off\", labelleft=\"on\")\n",
    "\n",
    "    # remove axis spines\n",
    "    ax.spines[\"top\"].set_visible(False)  \n",
    "    ax.spines[\"right\"].set_visible(False) \n",
    "    ax.spines[\"bottom\"].set_visible(False) \n",
    "    ax.spines[\"left\"].set_visible(False)    \n",
    " \n",
    "    plt.grid()\n",
    "    plt.tight_layout\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_scikit_lda(X_lda_sklearn, title='Default LDA via scikit-learn')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
